# Set min. snakemake version for compatability.
snakemake.utils.min_version("7.28.0")


configfile: "config.yaml"


# Import modules. ----

import sys
import pandas as pd

# Custom modules.
sys.path.insert(0, "scripts/")
import logging_setup
import sanity_checks

# Set up logging. ----

log = logging_setup.init_logger()

## Sanity checks of input data. ----

# Read sample metadata.
samples = pd.read_csv(config["path_samples"], sep="\t")

# Read barcodes.
barcodes = pd.read_csv(config["path_barcodes"], sep="\t", comment="#")

if not sanity_checks.sanity_barcodes(log, barcodes):
    raise ValueError("Barcode file is not valid.")

if not sanity_checks.sanity_samples(log, samples, barcodes, config):
    raise ValueError("Sample metadata is not valid.")

# Select unique samples for which to generate sample-specific files.
samples_unique = samples.drop_duplicates(
    subset=["sequencing_name", "sample_name", "species"]
)

# Close log file.
log.handlers[0].close()
log.removeHandler(log.handlers[0])


# Constrain wildcard values to resolve downstream mixtures. ----
wildcard_constraints:
    sequencing_name="|".join([re.escape(x) for x in samples_unique["sequencing_name"]]),
    sample_name="|".join([re.escape(x) for x in samples_unique["sample_name"]]),
    species="|".join([re.escape(x) for x in samples_unique["species"]]),


# Workflow output. ----


# Set working directory to output directory.
workdir: config["dir_output"]


rule DEMUX:
    input:
        lambda w: [
            "demultiplex_fastq/fastp/{sequencing_name}_{sample_name}_R1.fq.gz".format(
                sequencing_name=sequencing_name,
                sample_name=sample_name,
                species=species,
            )
            for sequencing_name, sample_name, species in zip(
                samples_unique["sequencing_name"],
                samples_unique["sample_name"],
                samples_unique["species"],
            )
        ],


# Load rules ----


include: "rules/step1_demultiplexing_fastq.smk"
